# RLM Implement Task Prompt

## Purpose
Implement a single task using Test-Driven Development (TDD) with configurable automation levels.

## Instructions for AI

You are the RLM Implementation Agent. Your job is to implement tasks following TDD methodology while respecting the project constitution.

---

## Phase 1: Setup

### Load Context
Read these files in order:
1. `RLM/specs/constitution.md` - Coding standards and conventions
2. `RLM/progress/status.json` - Current progress state
3. The specific task file: `RLM/tasks/active/TASK-XXX.md`
4. The parent feature spec: `RLM/specs/features/FTR-XXX/spec.md`

### Identify Task
If no task ID provided, check `RLM/progress/status.json` for:
- `currentTask` - Resume if exists
- Otherwise, find next pending task with no blockers

### Check Dependencies
Verify all tasks listed in "Dependencies" are completed.

If dependencies incomplete:
> "Cannot start TASK-XXX. Blocked by incomplete dependencies:
> - TASK-YYY: [Status]
> - TASK-ZZZ: [Status]
>
> Would you like to:
> 1. Implement the blocking task first
> 2. Skip to another task with no blockers
> 3. Mark dependency as not needed (with reason)"

---

## Phase 2: Select Automation Level

Ask the user (unless already specified):

> "Select automation level for implementation:
>
> **AUTO** - I'll make all decisions and implement without stopping
> - Best for: Straightforward tasks, experienced developers
>
> **SUPERVISED** - I'll pause at key decision points for approval
> - Best for: Most tasks, learning, code review checkpoints
>
> **MANUAL** - I'll explain and wait for approval before each step
> - Best for: Complex tasks, debugging, training
>
> Which level? (auto/supervised/manual)"

---

## Phase 3: Create Progress Log

Create/update `RLM/progress/logs/TASK-XXX.md`:

```markdown
# Implementation Log: TASK-XXX

## Task: [Task Title]
## Started: [Timestamp]
## Automation Level: [Level]
## Status: IN_PROGRESS

### Progress:
- [Timestamp] Started implementation
```

Update `RLM/progress/status.json`:
```json
{
  "lastUpdate": "[timestamp]",
  "currentTask": "TASK-XXX",
  "automationLevel": "[level]",
  "tasks": {
    "TASK-XXX": { "status": "in_progress", "startedAt": "[timestamp]" }
  }
}
```

---

## Phase 4: TDD Implementation

Follow this cycle for each piece of functionality:

### Step 1: Write Test First

**SUPERVISED/MANUAL**: Show proposed test and wait for approval

```
## Proposed Test

I'm creating a test for: [What the test covers]

File: `[test file path]`

```[language]
describe('[Component/Function]', () => {
  it('should [expected behavior] when [condition]', () => {
    // Arrange
    // Act
    // Assert
  });
});
```

Approve this test? (yes/modify/skip)
```

Write the test file. The test should FAIL initially (Red phase).

**AUTO**: Write tests without stopping, log what was created.

### Step 2: Run Tests (Verify Failure)

Run the test suite to confirm the new test fails:
- For JavaScript/TypeScript: `npm test` or `npx jest`
- For Python: `pytest`
- Adapt command to project's test runner

**SUPERVISED**: Report test failure
> "Test written and verified failing (expected). Proceeding to implementation."

### Step 3: Implement Code

Write the minimum code to make the test pass.

**SUPERVISED/MANUAL**: Show proposed implementation

```
## Proposed Implementation

File: `[implementation file path]`

```[language]
// Implementation code here
```

This implements: [Brief description]

Approve this implementation? (yes/modify)
```

**AUTO**: Implement without stopping, log what was created.

### Step 4: Run Tests (Verify Success)

Run tests again to confirm they pass (Green phase).

If tests fail:
- **AUTO**: Fix and retry up to 3 times, then pause for help
- **SUPERVISED/MANUAL**: Report failure and propose fix

### Step 5: Refactor (if needed)

Look for opportunities to improve code without changing behavior:
- Remove duplication
- Improve naming
- Extract functions
- Add documentation

**SUPERVISED**: Only pause if significant refactoring needed
**MANUAL**: Pause before any refactoring

### Repeat Cycle

Continue the TDD cycle until all acceptance criteria are met.

---

## Phase 5: Quality Checks (Enhanced with Review)

After implementation complete, run quality checks AND integrated review:

### 5.1 Automated Checks

```bash
# All tests pass
npm test  # or equivalent

# Linting clean
npm run lint  # or equivalent

# Type checking (if TypeScript)
npm run typecheck  # or npx tsc --noEmit
```

If any automated checks fail, fix before proceeding.

### 5.2 Security Check
- [ ] No hardcoded secrets
- [ ] No SQL injection vulnerabilities
- [ ] Input validation present
- [ ] Proper error handling (no stack traces exposed)
- [ ] No sensitive data in logs
- [ ] HTTPS/TLS for external calls

### 5.3 Constitution Compliance
- [ ] Naming conventions from constitution
- [ ] File structure from constitution
- [ ] Error handling patterns from constitution
- [ ] Documentation requirements from constitution

### 5.4 Design Compliance (if DESIGN_REQUIRED)

Check if project has UI components (read from constitution.md):
```
If DESIGN_REQUIRED == true:
```

- [ ] Design tokens used (no hardcoded colors, spacing, typography)
- [ ] All 8 component states implemented (default, hover, focus, active, disabled, loading, error, empty)
- [ ] ARIA attributes present for accessibility
- [ ] Keyboard navigation works
- [ ] Responsive at all breakpoints defined in design system
- [ ] Animation tier respected (MINIMAL/MODERATE/RICH)

### 5.5 Quick Review Checklist

Before marking task complete, verify:

**Code Quality:**
- [ ] Functions are < 50 lines
- [ ] No unused imports or variables
- [ ] Comments explain "why", not "what"
- [ ] Error messages are helpful

**Test Quality:**
- [ ] Tests cover happy path
- [ ] Tests cover edge cases (null, empty, boundary values)
- [ ] Tests cover error scenarios
- [ ] Test names describe behavior, not implementation

**Documentation:**
- [ ] Public APIs have JSDoc/docstrings
- [ ] Complex logic has inline comments
- [ ] README updated if API changed

### 5.6 Review Gate

**AUTO mode**:
- Run all checks programmatically
- Log results to progress log
- Continue if all pass
- Pause and report if any fail

**SUPERVISED mode**:
- Show checklist summary
- Report any issues found
- Ask: "All checks passed. Proceed to completion? (yes/no)"

**MANUAL mode**:
- Walk through each checklist item
- Explain what was checked
- Wait for explicit approval

### 5.7 Handle Issues

If any critical issues found during review:
1. Fix the issue before completing task
2. Re-run affected checks
3. Log issues that were fixed:
   ```
   Review Issues Fixed:
   - [SECURITY] Added input sanitization to user input field
   - [DESIGN] Added missing focus state to submit button
   ```

**SUPERVISED/MANUAL**: Report any issues found and propose fixes

---

## Phase 6: Complete Task

### Update Task File
Move from `RLM/tasks/active/TASK-XXX.md` to `RLM/tasks/completed/TASK-XXX.md`

Add completion info to the task file:
```markdown
## Completion
- **Completed At**: [Timestamp]
- **Files Created**: [List]
- **Files Modified**: [List]
- **Tests Added**: [Count]
- **Notes**: [Any relevant notes]
```

### Update Progress Log
```markdown
- [Timestamp] Implementation complete
- [Timestamp] All tests passing
- [Timestamp] Quality checks passed
- [Timestamp] Task marked complete

## Summary
- Files created: [List]
- Files modified: [List]
- Tests added: [Count]
- Total time: [Duration]
```

### Update Status
Update `RLM/progress/status.json`:
```json
{
  "lastUpdate": "[timestamp]",
  "currentTask": null,
  "tasks": {
    "TASK-XXX": { "status": "completed", "completedAt": "[timestamp]" }
  }
}
```

---

## Phase 6.5: Feature Completion Check (Automatic Verification)

After marking a task complete, check if this completes its parent feature.

### 6.5.1 Check Feature Status

```
1. Get parent feature ID from task metadata (FTR-XXX)
2. List all tasks for FTR-XXX:
   - Scan RLM/tasks/active/ for tasks with feature: FTR-XXX
   - Scan RLM/tasks/completed/ for tasks with feature: FTR-XXX
   - Scan RLM/tasks/blocked/ for tasks with feature: FTR-XXX

3. Calculate completion:
   - Total tasks: [count]
   - Completed: [count]
   - Active: [count]
   - Blocked: [count]
```

### 6.5.2 Feature Completion Detection

```
If all tasks for FTR-XXX are completed (active=0, blocked=0):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸŽ‰ Feature FTR-XXX Complete!                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ All tasks for this feature have been implemented:               â”‚
â”‚ - TASK-001 âœ“                                                   â”‚
â”‚ - TASK-002 âœ“                                                   â”‚
â”‚ - TASK-003 âœ“ (just completed)                                  â”‚
â”‚                                                                 â”‚
â”‚ Triggering automatic feature verification...                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.5.3 Automatic Feature Verification

When the last task of a feature completes:

**Step 1: Update Feature Status**
```json
// In RLM/progress/status.json
{
  "features": {
    "FTR-XXX": { "status": "verification-pending" }
  }
}
```

**Step 2: Generate E2E Tests**

Read the feature spec at `RLM/specs/features/FTR-XXX/spec.md`:
- Extract acceptance criteria
- Generate Playwright tests for each criterion
- Save tests to `rlm-app/tests/e2e/features/FTR-XXX/`

Test file structure:
```
rlm-app/tests/e2e/features/FTR-XXX/
â”œâ”€â”€ FTR-XXX.functional.test.ts  # Functional tests from acceptance criteria
â”œâ”€â”€ FTR-XXX.a11y.test.ts        # Accessibility tests (if DESIGN_REQUIRED)
â””â”€â”€ FTR-XXX.visual.test.ts      # Visual regression (if configured)
```

**Step 3: Run Verification Suite**

```bash
# Functional tests
npx playwright test tests/e2e/features/FTR-XXX/FTR-XXX.functional.test.ts

# Accessibility tests (if applicable)
npx playwright test tests/e2e/features/FTR-XXX/FTR-XXX.a11y.test.ts

# Visual regression (if configured)
npx playwright test tests/e2e/features/FTR-XXX/FTR-XXX.visual.test.ts
```

**Step 4: Handle Results**

**If ALL tests PASS:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Feature FTR-XXX VERIFIED                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Functional tests:    12/12 passed                               â”‚
â”‚ Accessibility tests: 8/8 passed (WCAG 2.1 AA compliant)        â”‚
â”‚ Visual regression:   No unexpected changes                      â”‚
â”‚                                                                 â”‚
â”‚ Feature status: verified                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Update status:
```json
{
  "features": {
    "FTR-XXX": {
      "status": "verified",
      "verified_at": "[timestamp]",
      "test_results": {
        "functional": { "passed": 12, "failed": 0 },
        "accessibility": { "passed": 8, "failed": 0 },
        "visual": { "changes": 0 }
      }
    }
  }
}
```

**If ANY tests FAIL:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ Feature FTR-XXX VERIFICATION FAILED                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Functional tests:    10/12 passed (2 failures)                  â”‚
â”‚ Accessibility tests: 7/8 passed (1 failure)                     â”‚
â”‚                                                                 â”‚
â”‚ Creating bug tasks for failures...                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Step 5: Create Bug Tasks (on failure)**

For each test failure, create a bug task:

```markdown
# TASK-XXX-BUG-001: [Test name] - Verification Failure

## Metadata
- **Feature**: FTR-XXX
- **Type**: bug
- **Priority**: critical
- **Source**: Feature verification
- **Generation**: [current]

## Description
Verification test failed for feature FTR-XXX.

## Failure Details
- **Test**: [Test file and name]
- **Expected**: [Expected behavior from test]
- **Actual**: [Actual behavior observed]
- **Error**: [Error message]

## Reproduction Steps
1. [Steps from test]

## Acceptance Criteria
- [ ] Test [test name] passes
- [ ] No regression in other tests

## Screenshot/Evidence
[Attach screenshot if available]
```

Save bug tasks to `RLM/tasks/active/TASK-XXX-BUG-NNN.md`

**Step 6: Update Feature Status (on failure)**
```json
{
  "features": {
    "FTR-XXX": {
      "status": "verification-failed",
      "failed_at": "[timestamp]",
      "bug_tasks": ["TASK-XXX-BUG-001", "TASK-XXX-BUG-002"],
      "test_results": {
        "functional": { "passed": 10, "failed": 2 },
        "accessibility": { "passed": 7, "failed": 1 }
      }
    }
  }
}
```

### 6.5.4 Re-Verification After Bug Fixes

When all bug tasks for a feature are completed:
1. Automatically trigger re-verification
2. Run only the previously failed tests
3. If all pass â†’ mark feature as verified
4. If still failing â†’ create new bug tasks

### 6.5.5 Feature Status Flow

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ in_progress â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ (all tasks completed)
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ verification-pending  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ (run E2E tests)
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                             â”‚
            â–¼                             â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ verified â”‚              â”‚ verification-failedâ”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚ (fix bugs)
                                          â–¼
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚ verification-pendingâ”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚ (re-run tests)
                                          â–¼
                                     (repeat)
```

---

## Phase 7: Report and Next Steps

Generate completion report:

```
## TASK-XXX Complete!

### Summary
- **Task**: [Title]
- **Duration**: [Time spent]
- **Files Created**: [Count]
- **Files Modified**: [Count]
- **Tests Added**: [Count]

### What Was Implemented
[Brief description of what was built]

### Files Changed
- Created: `path/to/new/file.ts`
- Modified: `path/to/existing/file.ts`

### Tests Added
- `path/to/test/file.test.ts`: [X] tests

### Next Task
The next task in the queue is:
**TASK-YYY**: [Title]
- Dependencies: [Met/Unmet]
- Priority: [Priority]

Would you like to:
1. Continue to TASK-YYY
2. Review the completed work
3. Stop for now (progress is saved)
```

---

## Handling Blockers

If implementation cannot proceed:

1. **Technical Blocker**: Missing dependency, unclear requirement
   - Document the blocker
   - Move task to `RLM/tasks/blocked/TASK-XXX.md`
   - Add blocker details to task file
   - Update status.json with blocker info
   - Suggest alternatives or ask for guidance

2. **Waiting for Input**: Need user decision
   - **AUTO**: Pause and ask
   - **SUPERVISED/MANUAL**: Ask immediately
   - Document the question and wait

3. **External Dependency**: Waiting on third-party, other team
   - Document the dependency
   - Move to blocked
   - Continue with unblocked tasks

---

## Automation Level Behaviors

### AUTO Mode
- Write tests and code without pausing
- Only pause for: Blockers, multiple failures, ambiguous requirements
- Log all decisions for review
- Best for: Small tasks, clear requirements, experienced reviewers

### SUPERVISED Mode
- Pause before: Starting implementation, after writing tests, after implementation, before refactoring
- Show summaries at each checkpoint
- Wait for approval: "Proceed? (yes/no)"
- Best for: Most development work

### MANUAL Mode
- Pause before every file write
- Explain reasoning for each decision
- Wait for explicit approval
- Best for: Learning, complex decisions, debugging

---

## Token/Progress Tracking

### 5-Step Progress Model

Each task follows these steps with percentage ranges:

| Step | Name | Range | Activities |
|------|------|-------|------------|
| 1 | Loading context | 0-10% | Read task file, feature spec, constitution |
| 2 | Writing tests | 10-40% | Create test file, write test cases |
| 3 | Implementing code | 40-70% | Write implementation to pass tests |
| 4 | Running tests | 70-85% | Execute tests, verify all pass |
| 5 | Quality checks | 85-100% | Lint, type-check, security review |

### Real-Time Progress Output

At each step, output progress indicator:

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“Š TASK-XXX: [Task Title]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 40% (Step 2/5: Writing tests)

Token Usage This Task:
  Input:  2,450 tokens
  Output: 1,230 tokens
  Total:  3,680 tokens

Session Total: 15,420 / 100,000 tokens (15.4%)

â±ï¸  Elapsed: 3m 24s | Est. Remaining: 5m 10s
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Step Transition Reporting

At the start of each step:
```
[Step 2/5] Writing tests...
```

At the end of each step:
```
âœ“ Step 2 complete: 4 tests written (12 assertions)
```

### Silent Logging (Always Active)

After each step, log to `RLM/progress/token-usage/session-YYYY-MM-DD.json`:

```json
{
  "session_id": "SESSION-2024-12-09-001",
  "started_at": "2024-12-09T10:00:00Z",
  "entries": [
    {
      "timestamp": "2024-12-09T10:05:00Z",
      "task": "TASK-XXX",
      "step": "writing_tests",
      "step_number": 2,
      "percentage": 40,
      "tokens": { "input": 1200, "output": 450 },
      "cumulative": { "input": 5000, "output": 2100 },
      "elapsed_ms": 45000,
      "notes": "4 tests written"
    }
  ],
  "summary": {
    "total_tokens": 0,
    "tasks_completed": 0,
    "avg_tokens_per_task": 0
  }
}
```

### Task Completion Summary

At task completion, output:

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… TASK-XXX COMPLETE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Duration: 8m 32s
Files Created: 2
Files Modified: 1
Tests Added: 4 (12 assertions)
Test Coverage: 94%

Token Usage:
  This Task:  8,450 tokens
  Session:   23,890 tokens (23.9%)

Next: TASK-YYY - [Title]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Configuration

Progress reporting is configured in `RLM/progress/cc-config.json`:

```json
{
  "reporting": {
    "mode": "both",
    "realtime": {
      "show_token_count": true,
      "show_progress_bar": true,
      "update_frequency": "per_step"
    },
    "logging": {
      "enabled": true,
      "granularity": "detailed"
    }
  }
}
```

Modes:
- `realtime` - Show progress output only
- `silent` - Log to file only
- `both` - Show output AND log to file (default)

---

## Notes for AI

- Always follow TDD: Test first, then implement
- Respect the constitution - it defines project standards
- Keep tasks focused - don't scope creep
- Document decisions in the progress log
- If uncertain, ask - especially in SUPERVISED mode
- Commit messages should follow constitution format
- Quality > Speed - better to pause than introduce bugs
